{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93410121-feaa-460f-938e-900d84f713a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e210338c-d5e6-4d90-adb4-59b155e52c70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "import requests\n",
    "import warnings\n",
    "import inflection\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "\n",
    "from scipy import stats as ss\n",
    "from boruta import BorutaPy\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e27019b-7448-45e3-aa27-0256650c291b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0.1 Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c764d7d-95be-42f9-a987-d2f4740d4d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cross_validation( x_training, kfold, model_name, model, verbose=False ):\n",
    "    mae_list = []\n",
    "    mape_list = []\n",
    "    rmse_list = []\n",
    "    for k in reversed( range( 1, kfold+1 ) ):\n",
    "        if verbose:\n",
    "            print( '\\nKFold Number: {}'.format( k ) )\n",
    "        # start and end date for validation\n",
    "        validation_start_date = x_training['date'].max() - datetime.timedelta(days=k*6*7)\n",
    "        validation_end_date = x_training['date'].max() - datetime.timedelta(days=(k-1)*6*7)\n",
    "        # filtering dataset\n",
    "        training = x_training[x_training['date'] < validation_start_date]\n",
    "        validation = x_training[(x_training['date'] >= validation_start_date) & (x_training['date'] <= validation_end_date)]\n",
    "        # training and validation dataset\n",
    "        # training\n",
    "        xtraining = training.drop( ['date', 'sales'], axis=1 )\n",
    "        ytraining = training['sales']\n",
    "        # validation\n",
    "        xvalidation = validation.drop( ['date', 'sales'], axis=1 )\n",
    "        yvalidation = validation['sales']\n",
    "        # model\n",
    "        m = model.fit( xtraining, ytraining )\n",
    "        # prediction\n",
    "        yhat = m.predict( xvalidation )\n",
    "        # performance\n",
    "        m_result = ml_error( model_name, np.expm1( yvalidation ), np.expm1(yhat ) )\n",
    "        # store performance of each kfold iteration\n",
    "        mae_list.append( m_result['MAE'] )\n",
    "        mape_list.append( m_result['MAPE'] )\n",
    "        rmse_list.append( m_result['RMSE'] )\n",
    "    return pd.DataFrame( {'Model Name': model_name,\n",
    "    'MAE CV': np.round( np.mean( mae_list ), 2 ).astype(str ) + ' +/- ' + np.round( np.std( mae_list \n",
    "                                                                            ), 2 ).astype( str ),\n",
    "    'MAPE CV': np.round( np.mean( mape_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mape_list \n",
    "                                                                            ), 2 ).astype( str ),\n",
    "    'RMSE CV': np.round( np.mean( rmse_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( rmse_list \n",
    "                                                                             ), 2 ).astype( str )}, index=[0] )\n",
    "\n",
    "def mean_percentage_error( y, yhat ):\n",
    "    return np.mean( ( y - yhat ) / y )\n",
    "\n",
    "def mean_absolute_percentage_error( y, yhat ):\n",
    "    return np.mean( np.abs( ( y - yhat ) / y ) )\n",
    "\n",
    "def ml_error( model_name, y, yhat ):\n",
    "    mae = mean_absolute_error( y, yhat )\n",
    "    mape = mean_absolute_percentage_error( y, yhat )\n",
    "    rmse = np.sqrt( mean_squared_error( y, yhat ) )\n",
    "    return pd.DataFrame( { 'Model Name': model_name,\n",
    "    'MAE': mae,\n",
    "    'MAPE': mape,\n",
    "    'RMSE': rmse }, index=[0] )\n",
    "\n",
    "\n",
    "def cramer_v( x, y ):\n",
    "    cm = pd.crosstab( x, y ).to_numpy()\n",
    "    n = cm.sum()\n",
    "    r, k = cm.shape\n",
    "    chi2 = ss.chi2_contingency( cm )[0]\n",
    "    chi2corr = max( 0, chi2 - (k-1)*(r-1)/(n-1) )\n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    rcorr = r - (r-1)**2/(n-1)\n",
    "    return np.sqrt( (chi2corr/n) / ( min( kcorr-1, rcorr-1 ) ) )\n",
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [25, 12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    display( HTML( '<style>.container { width:100% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "    sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa2277c8-40c6-4efe-aede-18f27e9e278c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30fe9b-8f67-4535-b3d0-d8ebf143eda8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0.2 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "896dd843-0719-438b-b238-c39472ef31cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sales_raw = pd.read_csv('data\\\\train.csv', low_memory=False)\n",
    "df_store_raw = pd.read_csv('data\\\\store.csv', low_memory=False)\n",
    "df_raw = pd.merge(df_sales_raw, df_store_raw, how='left', on='Store')\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f552c0e8-534e-47e1-96fe-7ce7e1097a23",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1.0 Descrição dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cf3edfb-fef0-4038-b626-2f7063d82b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eaf24c-7478-4752-8666-667aac4732d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6702b88-3fae-4748-bebe-85722b616036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_old = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
    "       'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
    "       'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "       'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
    "       'Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "snakecase = lambda x: inflection.underscore( x )\n",
    "cols_new = list (map(snakecase, cols_old))\n",
    "df1.columns = cols_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4173d57-0bc1-4c9c-ac36-5357377b6598",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2 Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f13228-45ce-4b92-a83d-12cb5fd3bf6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (f'Number of Rows: {df1.shape[0]}')\n",
    "print (f'Number of Cols: {df1.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b6ad3c-a140-47fd-addb-6c02775210ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.3 Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5b04c-253f-4a4b-85cc-ebaae673870a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1['date'] = pd.to_datetime( df1['date'])\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f894ee30-a925-40e9-9185-be0126f0e2c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.4 Check NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb94aeb0-4127-4295-955e-73b8192a35af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23818da8-a401-4142-ad43-0243bae31714",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.5 Fillout NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae64c13-0beb-481f-bd90-79cc81e8ed37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#competition_distance\n",
    "df1['competition_distance'] = df1['competition_distance'].apply( lambda x:200000.0 if math.isnan( x ) else x )\n",
    "#competition_open_since_month\n",
    "df1['competition_open_since_month'] = df1.apply( lambda x: x['date'].month if math.isnan( x['competition_open_since_month'] ) else x['competition_open_since_month'], axis=1 )\n",
    "#competition_open_since_year\n",
    "df1['competition_open_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['competition_open_since_year'] ) else\n",
    "x['competition_open_since_year'], axis=1 )\n",
    "#promo2_since_week\n",
    "df1['promo2_since_week'] = df1.apply( lambda x: x['date'].week if math.isnan(x['promo2_since_week'] ) else x['promo2_since_week'], axis=1 )\n",
    "#promo2_since_year\n",
    "df1['promo2_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan(x['promo2_since_year'] ) else x['promo2_since_year'], axis=1 )\n",
    "#promo_interval\n",
    "month_map = {1: 'Jan', 2: 'Fev', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "df1['promo_interval'].fillna(0, inplace=True )\n",
    "df1['month_map'] = df1['date'].dt.month.map( month_map )\n",
    "df1['is_promo'] = df1[['promo_interval', 'month_map']].apply( lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split( ',' ) else 0, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54359d22-5214-410d-b15f-de22d22f2b67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55870253-cba2-4f39-a506-a314309d45dc",
   "metadata": {},
   "source": [
    "## 1.6. Change Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5087b540-a692-476b-9423-58759e801d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# competiton\n",
    "df1['competition_open_since_month'] = df1['competition_open_since_month'].astype( int )\n",
    "df1['competition_open_since_year'] = df1['competition_open_since_year'].astype(int )\n",
    "# promo2\n",
    "df1['promo2_since_week'] = df1['promo2_since_week'].astype( int )\n",
    "df1['promo2_since_year'] = df1['promo2_since_year'].astype( int )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae492bbf-4f64-4e6f-8d71-509e98b2d312",
   "metadata": {},
   "source": [
    "## 1.7 Descriptive statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb45b1-07c8-4c6e-94f0-8edeb81c30c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_attributes = df1.select_dtypes( include=['int64', 'int32', 'float64'] )\n",
    "cat_attributes = df1.select_dtypes( exclude=['int64', 'int32', 'float64','datetime64[ns]'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd322f41-99cd-4b7c-9f08-44c1ab9115b0",
   "metadata": {},
   "source": [
    "##  1.7.1. Numerical Atributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a5bd1-917f-455a-bcc6-081c5135621f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Central Tendency - mean, meadina\n",
    "ct1 = pd.DataFrame( num_attributes.apply( np.mean ) ).T\n",
    "ct2 = pd.DataFrame( num_attributes.apply( np.median ) ).T\n",
    "# dispersion - std, min, max, range, skew, kurtosis\n",
    "d1 = pd.DataFrame( num_attributes.apply( np.std ) ).T\n",
    "d2 = pd.DataFrame( num_attributes.apply( min ) ).T\n",
    "d3 = pd.DataFrame( num_attributes.apply( max ) ).T\n",
    "d4 = pd.DataFrame( num_attributes.apply( lambda x: x.max() - x.min() ) ).T\n",
    "d5 = pd.DataFrame( num_attributes.apply( lambda x: x.skew() ) ).T\n",
    "d6 = pd.DataFrame( num_attributes.apply( lambda x: x.kurtosis() ) ).T\n",
    "# concatenar\n",
    "m = pd.concat( [d2, d3, d4, ct1, ct2, d1, d5, d6] ).T.reset_index()\n",
    "m.columns = ['attributes', 'min', 'max', 'range', 'mean', 'median', 'std','skew', 'kurtosis']\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df38a581-fcc3-4df6-ae06-b3761df2c152",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.histplot( df1['competition_distance'], kde=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc36aa8-7650-4cda-a7c3-6700016c8364",
   "metadata": {},
   "source": [
    "##  1.7.2. Categorical Atributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd8d02e-63e1-461e-afcd-6a2472dc41df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " cat_attributes.apply( lambda x: x.unique().shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b2806e-d1ed-4236-bbc7-4a57c23f6065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux = df1[(df1['state_holiday'] != '0') & (df1['sales'] > 0)]\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.boxplot( x='state_holiday', y='sales', data=aux )\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.boxplot( x='store_type', y='sales', data=aux )\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.boxplot( x='assortment', y='sales', data=aux )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9955f9c2-edfe-4c75-9d14-937c3d35cb85",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  2.0. PASSO 02 - FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba77fbf-c1cc-4b6c-9edf-328c28d328ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c4079-69f0-412f-8009-b491ae8de044",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1. Mapa Mental de Hipoteses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b85a92-95de-4735-bdad-2a051c54b4af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image( 'img\\\\daily_store_sales.png' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364701b6-16c1-4b4b-85cf-e124179b1509",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2. Criacao das Hipoteses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d75eda-f791-450d-b288-59e0b4a6affd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2.2.1. Hipoteses Loja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1203be-9c2f-40ae-8568-b1ce0713ef34",
   "metadata": {},
   "source": [
    "####\n",
    "1. Lojas com número maior de funcionários deveriam vender mais.\n",
    "2. Lojas com maior capacidade de estoque deveriam vender mais.\n",
    "3. Lojas com maior porte deveriam vender mais.\n",
    "4. Lojas com maior sortimentos deveriam vender mais.\n",
    "5. Lojas com competidores mais próximos deveriam vender menos.\n",
    "6. Lojas com competidores à mais tempo deveriam vendem mais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21896a4f-6520-4086-a59e-845c1fab63cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2.2.2. Hipoteses Produto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af48bf-ea6e-4714-a32a-a69ccda02c45",
   "metadata": {},
   "source": [
    "####\n",
    "1. Lojas que investem mais em Marketing deveriam vender mais.\n",
    "2. Lojas com maior exposição de produto deveriam vender mais.\n",
    "3. Lojas com produtos com preço menor deveriam vender mais.\n",
    "5. Lojas com promoções mais agressivas ( descontos maiores ), deveriam vender mais.\n",
    "6. Lojas com promoções ativas por mais tempo deveriam vender mais.\n",
    "8. Lojas com mais promoções consecutivas deveriam vender mais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13277f3c-3100-43d0-9069-7db73f1fcde0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2.2.2. Hipoteses Tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea991e52-dd7c-4ba5-b941-ac7000d7767c",
   "metadata": {},
   "source": [
    "####\n",
    "1. Lojas abertas durante o feriado de Natal deveriam vender mais.\n",
    "2. Lojas deveriam vender mais ao longo dos anos.\n",
    "3. Lojas deveriam vender mais no segundo semestre do ano.\n",
    "4. Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
    "5. Lojas deveriam vender menos aos finais de semana.\n",
    "6. Lojas deveriam vender menos durante os feriados escolares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1356acdf-958b-46e0-9f78-1883437f2b63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2.3. Lista Final de Hipóteses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c994c7e-aa60-4e9e-88b8-c2a872cf1ebd",
   "metadata": {},
   "source": [
    "####\n",
    "1. Lojas com maior sortimentos deveriam vender mais.\n",
    "2. Lojas com competidores mais próximos deveriam vender menos.\n",
    "3. Lojas com competidores à mais tempo deveriam vendem mais.\n",
    "4. Lojas com promoções ativas por mais tempo deveriam vender mais.\n",
    "5. Lojas com mais promoções consecutivas deveriam vender mais.\n",
    "6. Lojas abertas durante o feriado de Natal deveriam vender mais.\n",
    "7. Lojas deveriam vender mais ao longo dos anos.\n",
    "8. Lojas deveriam vender mais no segundo semestre do ano.\n",
    "9. Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
    "10. Lojas deveriam vender menos aos finais de semana.\n",
    "11. Lojas deveriam vender menos durante os feriados escolares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567c4460-53f4-430c-98ab-c8752780ff02",
   "metadata": {},
   "source": [
    "### 2.4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c6bc5-a889-4c49-85be-7c5fced870f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# year\n",
    "df2['year'] = df2['date'].dt.year\n",
    "# month\n",
    "df2['month'] = df2['date'].dt.month\n",
    "# day\n",
    "df2['day'] = df2['date'].dt.day\n",
    "# week of year\n",
    "df2['week_of_year'] = df2['date'].dt.isocalendar().week\n",
    "# year week\n",
    "df2['year_week'] = df2['date'].dt.strftime( '%Y-%W' )\n",
    "# competition since\n",
    "df2['competition_since'] = df2.apply( lambda x: datetime.datetime(year=x['competition_open_since_year'],\n",
    "                                                                  month=x['competition_open_since_month'],day=1 ), axis=1 )\n",
    "df2['competition_time_month'] = ( ( df2['date'] - df2['competition_since'] )/30).apply( lambda x: x.days ).astype( int )\n",
    "# promo since\n",
    "df2['promo_since'] = df2['promo2_since_year'].astype( str ) + '-' + df2['promo2_since_week'].astype( str )\n",
    "df2['promo_since'] = df2['promo_since'].apply( lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w' ) - datetime.timedelta( days=7 ) )\n",
    "df2['promo_time_week'] = ( ( df2['date'] - df2['promo_since'] )/7 ).apply(lambda x: x.days ).astype( int )\n",
    "# assortment\n",
    "df2['assortment'] = df2['assortment'].apply( lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended' )\n",
    "# state holiday\n",
    "df2['state_holiday'] = df2['state_holiday'].apply( lambda x: 'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4977d5-551e-43a2-8d6f-7ebe96524e71",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 3.0. PASSO 03 - FILTRAGEM DE VARIÁVEIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcaaf19-e4f2-4ae8-80b9-c09b5aa87512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf948d2-265a-470c-b946-2ac4b251d1da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.1. Filtragem das Linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e4f9dc-c57c-464d-8da9-844f05953311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df3 = df3[(df3['open'] != 0) & (df3['sales'] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9340f2b2-5fc2-4042-bf33-e4cea971ade0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.2. Selecao das Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee159134-4da2-41eb-aafa-6ad7e1674c9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_drop = ['customers', 'open', 'promo_interval', 'month_map']\n",
    "df3 = df3.drop( cols_drop, axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3b0ee7-a777-43e1-807c-f5e839a6767c",
   "metadata": {
    "tags": []
   },
   "source": [
    " # 4.0. PASSO 04 - ANALISE EXPLORATORIA DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c78a1-43d3-4ad2-993d-bf6b40aebd55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14826caf-d1cf-4d32-bd27-4ce3a53d0a0c",
   "metadata": {
    "tags": []
   },
   "source": [
    " ## 4.1. Analise Univariada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3480742e-dfe0-48d0-98b3-3ad5e15a5b0f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 4.1.1. Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924cced8-872f-4d9b-bc60-68de39690d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.displot( df4['sales'], kde=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cd3f93-7811-4fa1-856e-d69b41e38b71",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 4.1.2. Numerical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde2c4ec-5c62-4692-822a-b595d35fafaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_attributes.hist( bins=25, histtype='barstacked', figsize=(12, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d46fd4a-e476-4b3d-a31d-708c81c57c80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###  4.1.3. Categorical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f1fc4-d763-4f33-8974-fc296fdc0865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# state_holiday\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.subplot( 3, 2, 1 )\n",
    "df_holiday = df4[df4['state_holiday'] != 'regular_day'].reset_index()\n",
    "sns.countplot(x='state_holiday', data=df_holiday)\n",
    "plt.title('Contagem de Feriados do Estado')\n",
    "plt.xlabel('Tipo de Feriado')\n",
    "plt.ylabel('Contagem')\n",
    "plt.subplot( 3, 2, 2 )\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'public_holiday']['sales'], label='public_holiday', fill=True)\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'easter_holiday']['sales'], label='easter_holiday', fill=True)\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'christmas']['sales'], label='christmas', fill=True)\n",
    "plt.legend()\n",
    "plt.title('Distribuição variável reposta - Feriados do Estado')\n",
    "plt.xlabel('vendas')\n",
    "plt.ylabel('densidade')\n",
    "\n",
    "# store_type\n",
    "plt.subplot( 3, 2, 3 )\n",
    "# Conta os valores únicos na coluna 'store_type'\n",
    "store_type_counts = df4['store_type'].value_counts()\n",
    "\n",
    "# Cria o gráfico de barras com base nos valores contados\n",
    "sns.barplot(x=store_type_counts.index, y=store_type_counts.values)\n",
    "plt.title('Contagem de tipos de loja')\n",
    "plt.xlabel('Tipo de loja')\n",
    "plt.ylabel('Contagem')\n",
    "plt.subplot( 3, 2, 4 )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'a']['sales'], label='a', fill=True )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'b']['sales'], label='b', fill=True )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'c']['sales'], label='c', fill=True )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'd']['sales'], label='d', fill=True )\n",
    "plt.legend()\n",
    "plt.title('Distribuição variável reposta - Tipo de loja')\n",
    "plt.xlabel('vendas')\n",
    "plt.ylabel('densidade')\n",
    "# assortment\n",
    "plt.subplot( 3, 2, 5 )\n",
    "#sns.countplot( df4['assortment'] )\n",
    "assortment_count = df4['assortment'].value_counts()\n",
    "sns.barplot(x=assortment_count.index, y=assortment_count.values)\n",
    "plt.title('Contagem de tipos de sortimento')\n",
    "plt.xlabel('Tipo de sortimento')\n",
    "plt.ylabel('Contagem')\n",
    "plt.subplot( 3, 2, 6 )\n",
    "sns.kdeplot( df4[df4['assortment'] == 'extended']['sales'], label='extended', fill=True )\n",
    "sns.kdeplot( df4[df4['assortment'] == 'basic']['sales'], label='basic', fill=True )\n",
    "sns.kdeplot( df4[df4['assortment'] == 'extra']['sales'], label='extra', fill=True )\n",
    "plt.legend()\n",
    "plt.title('Distribuição variável reposta - Sortimento')\n",
    "plt.xlabel('vendas')\n",
    "plt.ylabel('densidade')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c3dc34-7db7-47c1-9583-055e37d743b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.2. Analise Bivariada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a5ac39-ec46-4de9-bb54-03fa6fe6ed1e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### H1. Lojas com maior sortimentos deveriam vender mais\n",
    "Verdadeira, conforme o gráfico quanto maior o tipo de sortimento, maior é a média de vendas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f75f28-b63f-417d-a869-b2ab6c7ede91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['assortment', 'sales']].groupby( 'assortment' ).mean().reset_index()\n",
    "sns.barplot( x='assortment', y='sales', data=aux1 );\n",
    "aux2 = df4[['year_week', 'assortment', 'sales']].groupby(['year_week','assortment'] ).mean().reset_index()\n",
    "aux2.pivot( index='year_week', columns='assortment', values='sales' ).plot()\n",
    "aux3 = aux2[aux2['assortment'] == 'extra']\n",
    "aux3.pivot( index='year_week', columns='assortment', values='sales' ).plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b89e15f-8254-4407-b106-e7320ebf4d8a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### H2. Lojas com competidores mais próximos deveriam vender menos\n",
    "Falso. Usando como parâmetro a média (pois o volume de lojas com competidores mais próximo é significativamente maior, dessa forma um parâmetro de soma não faria sentido), podemos observar que não existe uma significativa diferença na média de vendas em relação a distancia do competidor. Os maiores valores de média acabam se encontrando em lojas com competidores mais próximos, mas são poucos pontos, o que não seria o suficiente para afirmar o oposto (que lojas com competidores mais próximos vendem mais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91de6cfe-4a32-4b66-9687-7ef500a113d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['competition_distance', 'sales']].groupby('competition_distance').mean().reset_index()\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot( 3, 1, 1 )\n",
    "sns.scatterplot(x='competition_distance', y='sales', data=aux1)\n",
    "\n",
    "plt.subplot( 3, 1, 2 )\n",
    "#como temos muitos dados, criamos bins para uma visualização mais concreta\n",
    "bins = list( np.arange( 0, 20000, 1000) )\n",
    "aux1['competition_distance_binned'] = pd.cut( aux1['competition_distance'], bins=bins )\n",
    "aux2 = aux1[['competition_distance_binned', 'sales']].groupby('competition_distance_binned' ).mean().reset_index()\n",
    "sns.barplot( x='competition_distance_binned', y='sales', data=aux2 )\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "numeric_columns = aux1.select_dtypes(include=['number'])\n",
    "x = sns.heatmap( numeric_columns.corr( method='pearson', numeric_only=False ), annot=True );\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa4f624-0587-4c74-a8f1-c81d965cf3d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### H3. Lojas com competidores à mais tempo deveriam vender mais. \n",
    "Falso. Não conseguimos identificar um padrão de comportamento influênciado pela variável.Entretanto a correlação apresentada é alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b27bb36-a31d-417a-87e2-04b019a78b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['competition_time_month', 'sales']].groupby('competition_time_month').mean().reset_index()\n",
    "# como o gráfico levando em consideraçao todo o período ficou muito extenso e não é possível tirar grandes conclusões, filtramos parte do perído \n",
    "aux2 = aux1[( aux1['competition_time_month'] < 120 ) & (aux1['competition_time_month'] != 0 )]\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot( 3, 1, 1 )\n",
    "sns.barplot( x='competition_time_month', y='sales', data=aux2 )\n",
    "plt.xticks( rotation=90 );\n",
    "plt.subplot( 3, 1, 2 )\n",
    "sns.regplot( x='competition_time_month', y='sales', data=aux2 );\n",
    "plt.subplot( 3, 1, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson'), annot=True, vmin=-1, vmax=1  );\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddcb576-b7fc-4493-83c2-b072a15bff85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### H4. Lojas com promoções ativas por mais tempo deveriam vender mais.\n",
    "Verdadeiro. Ao juntar períodos mais longos de promoção, conseguimos observar uma curva de comportamento ascendente no gráfico de tendência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe84aa5-6b18-44fe-90f2-3221dcd61a7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['promo_time_week', 'sales']].groupby( 'promo_time_week').mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.subplot(5,1,1 )\n",
    "aux2 = aux1[aux1['promo_time_week'] > 0] # promo extendido\n",
    "sns.barplot( x='promo_time_week', y='sales', data=aux2 );\n",
    "plt.xticks( rotation=90 );\n",
    "plt.subplot( 5,1,2)\n",
    "sns.regplot( x='promo_time_week', y='sales', data=aux2 );\n",
    "plt.subplot( 5,1,3)\n",
    "aux3 = aux1[aux1['promo_time_week'] < 0] # promo regular\n",
    "sns.barplot( x='promo_time_week', y='sales', data=aux3 );\n",
    "plt.xticks( rotation=90 );\n",
    "plt.subplot( 5,1,4)\n",
    "sns.regplot( x='promo_time_week', y='sales', data=aux3 );\n",
    "plt.subplot(5,1,5)\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True, vmin=-1, vmax=1  );\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1544e3-cd04-42fb-955f-20ca63fc5c97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### H5. Lojas com mais promoções consecutivas deveriam vender mais.\n",
    "Falso. Na média, lojas apenas com a primeira promoção ativa, possuem mais vendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6440d5ab-9053-46bc-8301-b8e14f5b4edc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['promo', 'promo2', 'sales']].groupby( ['promo', 'promo2']).mean().reset_index()\n",
    "aux1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cef6226-0f0e-4bc4-9e07-8f2180467245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux1 = df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 1 )][['year_week','sales']].groupby( 'year_week' ).mean().reset_index()\n",
    "ax = aux1.plot()\n",
    "aux2 = df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 0 )][['year_week','sales']].groupby( 'year_week' ).mean().reset_index()\n",
    "aux2.plot( ax=ax )\n",
    "ax.legend( labels=['Tradicional & Extendida', 'Tradicional']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4961a55f-57cd-4e62-9287-1d805df4264c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### H6. Lojas deveriam vender mais no feriado de natal\n",
    "Verdadeiro, porém a média de vendas é um pouco maior no feriado de páscoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0361418b-e60b-4a91-a2f0-d08ab44ab1a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['state_holiday', 'sales']].groupby('state_holiday').mean().reset_index()\n",
    "sns.barplot( x='state_holiday', y='sales', data=aux1 );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8cde7a-5702-4452-983e-fae493821422",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### H7. Lojas deveriam vender mais ao longo dos anos.\n",
    "Verdadeiro. Para esse análise decidimos usar como base a média também, pois o ano de 2013 tem mais registros que 2014 e 2015 ainda não está completo. Podemos observar um padrão de crescimento ao longo dos anos\n",
    "O mapa de correlação indica uma alta correlação entre a variável year e a variával resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb6b9ff-2330-414e-8301-b2da093c4e15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "aux1 = df4[['year', 'sales']].groupby('year').mean().reset_index()\n",
    "plt.subplot(1,2,1)\n",
    "sns.barplot( x='year', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c20ed3f-a7b8-4a59-97e5-2b5406313e89",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### H8. Lojas deveriam vender mais no segundo semestre do ano.\n",
    "Verdadeira. A média de vendas no segundo semestre é maior, principalmente por conta de um aumento significativo no mês de dezembro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ef814a-aacd-4b5c-b47f-63c206baf586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['month', 'sales']].groupby('month').mean().reset_index()\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(1,2,1)\n",
    "sns.barplot(x='month', y='sales', data=aux1)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True, vmin=-1, vmax=1  );\n",
    "plt.tight_layout()\n",
    "\n",
    "sem1 = df4.loc[df4['month'] <= 6, 'sales'].mean()\n",
    "sem2 = df4.loc[ df4['month'] > 6 , 'sales'].mean()\n",
    "data = {'semestre': ['1º Semestre', '2º Semestre'],\n",
    "        'média': [sem1, sem2]}\n",
    "df_media_semestre = pd.DataFrame(data)\n",
    "df_media_semestre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c54c2-31a3-4ca8-85a9-8d55898de2f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### H9. Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
    "Falso. Se olhar a média de vendas do período depois do dia 10, ela realmente é um pouco maior. Entretando quando olhamos dia a dia, não conseguimos observar um padrão de comportamento, temos médias altas e baixas em ambos períodos. Quando olhamos a correlação ela também é baixa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec245ac-18ae-4db5-9ab2-d0187785a610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['day','sales']].groupby('day').mean().reset_index()\n",
    "plt.subplot(2,1,1)\n",
    "sns.barplot( x='day', y='sales', data=aux1 );\n",
    "\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True, vmin=-1, vmax=1 );\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "aux = df4.loc[df4['day'] > 10, 'sales'].mean()\n",
    "aux1 = df4.loc[df4['day'] <= 10, 'sales'].mean()\n",
    "data = {'período': ['ate dia 10', 'depois dia 10'],\n",
    "        'média': [aux, aux1]}\n",
    "df_media_dias = pd.DataFrame(data)\n",
    "df_media_dias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca66601c-6398-4cc6-9404-e2dc7afcd146",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### H10. Lojas deveriam vender menos aos finais de semana.\n",
    "Falso. Considerando o dia 1 como domingo e o dia 7 como sábado. Lojas vendem mais no final de semana (são as duas médias mais altas).\n",
    "Quando avaliamos a correlação ela é baixa, indicando que a variável não tem muita ligação com a variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12daa3a-9c43-4c31-a52a-0c059fa1a6e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['day_of_week','sales']].groupby('day_of_week').mean().reset_index()\n",
    "plt.subplot(2,1,1)\n",
    "sns.barplot( x='day_of_week', y='sales', data=aux1 );\n",
    "\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True, vmin=-1, vmax=1   );\n",
    "plt.tight_layout()\n",
    "\n",
    "aux = df4.loc[(df4['day_of_week'] == 1) | (df4['day_of_week'] == 7) , 'sales'].mean()\n",
    "aux1 = df4.loc[(df4['day_of_week'] != 1) & (df4['day_of_week'] != 7) , 'sales'].mean()\n",
    "data = {'período': ['final de semana', 'dia de semana'],\n",
    "        'média': [aux, aux1]}\n",
    "df_media = pd.DataFrame(data)\n",
    "df_media\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393df42-33a4-498e-8b6c-adf759135133",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### H11. Lojas deveriam vender menos durante os feriados escolares.\n",
    "Falso.  Com base  na média, o valor de vendas é maior um pouco maior em dias de feriados escolares. Quando olhamos para os feriados mês a mês. nota-se que todos os meses, os dias de feriados possuem uma maior média, com exceção apenas de dezembro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92a5479-6a94-4c18-8a14-ec8e6adba50f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['school_holiday', 'sales']].groupby('school_holiday').mean().reset_index()\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "sns.barplot(x='school_holiday', y='sales', data=aux1)\n",
    "\n",
    "aux2 = df4[['month', 'school_holiday', 'sales']].groupby(['month','school_holiday']).mean().reset_index()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.barplot(x='month', y='sales', hue='school_holiday', data=aux2)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6f87d2-d287-4ecf-b565-3cd777c965cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2.1. Resumo das Hipoteses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db5e91-fc4e-40f9-a027-fb3ec6e2cfeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab =[['Hipoteses', 'Conclusao', 'Relevancia'], \n",
    "      ['H1', 'Verdadeira', 'Alta'], \n",
    "      ['H2', 'Falsa', 'Baixa'],\n",
    "['H3', 'Falsa', 'Alta'],\n",
    "['H4', 'Verdadeira', 'Media'],\n",
    "['H5', 'Falsa', 'Baixa'],\n",
    "['H6', 'Verdadeira', 'Media'],\n",
    "['H7', 'Verdadeira', 'Alta'],\n",
    "['H8', 'Verdadeira', 'Alta'],\n",
    "['H9', 'Falsa', 'Baixa'],\n",
    "['H10', 'Falsa', 'Baixa'],\n",
    "['H11', 'Falsa', 'Alta'],\n",
    "]\n",
    "print( tabulate( tab, headers='firstrow' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b73c0a1-5f31-47cc-b681-60f876df149c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4.3. Analise Multivariada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b6a48f-d3be-4e99-b53a-59e943dbc4cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.3.1. Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18782a96-c1db-4a4c-8f77-f4d3cb4a35ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = num_attributes.corr( method='pearson' )\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap( correlation, annot=True, vmin=-1, vmax=1  );\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3fee97-6bd2-4b79-a368-535d1a08d2d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.3.2. Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74100f37-24e1-4554-ab63-6ef7f454ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only categorical data\n",
    "a = df4.select_dtypes( include='object' )\n",
    "# Calculate cramer V\n",
    "a1 = cramer_v( a['state_holiday'], a['state_holiday'] )\n",
    "a2 = cramer_v( a['state_holiday'], a['store_type'] )\n",
    "a3 = cramer_v( a['state_holiday'], a['assortment'] )\n",
    "a4 = cramer_v( a['store_type'], a['state_holiday'] )\n",
    "a5 = cramer_v( a['store_type'], a['store_type'] )\n",
    "a6 = cramer_v( a['store_type'], a['assortment'] )\n",
    "a7 = cramer_v( a['assortment'], a['state_holiday'] )\n",
    "a8 = cramer_v( a['assortment'], a['store_type'] )\n",
    "a9 = cramer_v( a['assortment'], a['assortment'] )\n",
    "# Final dataset\n",
    "d = pd.DataFrame( {'state_holiday': [a1, a2, a3],'store_type': [a4, a5, a6],'assortment': [a7, a8, a9] })\n",
    "d = d.set_index( d.columns )\n",
    "sns.heatmap( d, annot=True, vmin=-1, vmax=1  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31882416-fdbe-44cb-b21d-e18ad680f6e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5.0. PASSO 05 - DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e544971-f5fa-4bf0-8ebf-8d4b32c8437e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e7ce0c-b6dd-40e3-aa64-e221bcdd7240",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 5.1. Normalizacao\n",
    "O dataset não possui nenhuma variável com uma distribuição gaussiana o que não torna viável o uso dessa reescala"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2c9c06-9563-47b1-b42c-ff6d48e7ebe2",
   "metadata": {},
   "source": [
    "## 5.2. Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178469bb-8c35-4be6-b709-ffbc9ffb71bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rs = RobustScaler()\n",
    "mms = MinMaxScaler()\n",
    "# competition distance\n",
    "df5['competition_distance'] = rs.fit_transform( df5[['competition_distance']].values )\n",
    "pickle.dump( rs, open( 'parameter\\\\competition_distance_scaler.pkl', 'wb') )\n",
    "\n",
    "# competition time month\n",
    "df5['competition_time_month'] = rs.fit_transform(df5[['competition_time_month']].values )\n",
    "pickle.dump( rs, open( 'parameter\\\\competition_time_month_scaler.pkl', 'wb') )\n",
    "\n",
    "# promo time week\n",
    "df5['promo_time_week'] = mms.fit_transform( df5[['promo_time_week']].values )\n",
    "pickle.dump( rs, open( 'parameter\\\\promo_time_week_scaler.pkl', 'wb') )\n",
    "\n",
    "# year\n",
    "df5['year'] = mms.fit_transform( df5[['year']].values )\n",
    "pickle.dump( mms, open( 'parameter\\\\year_scaler.pkl', 'wb') )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525a9913-b7ce-4b53-9f95-21c40b2ee8e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.3. Transformacao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19560aca-214e-4a65-9cf9-0f3065bee245",
   "metadata": {},
   "source": [
    "### 5.3.1. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30375d5e-0c16-4b01-9af8-f0099fadb03a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# state_holiday - One Hot Encoding\n",
    "df5 = pd.get_dummies( df5, prefix=['state_holiday'], columns=['state_holiday'] )\n",
    "\n",
    "# store_type - Label Encoding\n",
    "le = LabelEncoder()\n",
    "df5['store_type'] = le.fit_transform( df5['store_type'] )\n",
    "pickle.dump( le, open( 'parameter/store_type_scaler.pkl', 'wb') )\n",
    "\n",
    "# assortment - Ordinal Encoding\n",
    "assortment_dict = {'basic': 1, 'extended': 2, 'extra': 3} \n",
    "df5['assortment'] = df5['assortment'].map( assortment_dict )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ae5c1-43c9-4970-8bcb-7e1c5b0faa89",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.3.2. Response Variable Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edb96af-89db-42f5-9c52-b65802d8217b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df5['sales'] = np.log1p( df5['sales'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f200c518-387d-47af-9ae2-bdd96294ab58",
   "metadata": {},
   "source": [
    "### 5.3.3. Nature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8592ad72-c3d5-4bba-a4ed-4e677acf8b65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# day of week\n",
    "df5['day_of_week_sin'] = df5['day_of_week'].apply( lambda x: np.sin( x * ( 2. *np.pi/7 ) ) )\n",
    "df5['day_of_week_cos'] = df5['day_of_week'].apply( lambda x: np.cos( x * ( 2. *np.pi/7 ) ) )\n",
    "# month\n",
    "df5['month_sin'] = df5['month'].apply( lambda x: np.sin( x * ( 2. * np.pi/12 )) )\n",
    "df5['month_cos'] = df5['month'].apply( lambda x: np.cos( x * ( 2. * np.pi/12 )) )\n",
    "# day\n",
    "df5['day_sin'] = df5['day'].apply( lambda x: np.sin( x * ( 2. * np.pi/30 ) ) )\n",
    "df5['day_cos'] = df5['day'].apply( lambda x: np.cos( x * ( 2. * np.pi/30 ) ) )\n",
    "# week of year\n",
    "df5['week_of_year_sin'] = df5['week_of_year'].apply( lambda x: np.sin( x * ( 2.* np.pi/52 ) ) )\n",
    "df5['week_of_year_cos'] = df5['week_of_year'].apply( lambda x: np.cos( x * ( 2.* np.pi/52 ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7049d759-c98d-4406-81c9-2dc1af72a192",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 6.0 PASSO 06 - FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f204bca-acc9-4df6-be50-617f58b3c5b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df6 = df5.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b042a699-3bbb-4159-b27b-f094db0c45cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6.1. Split dataframe into training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495d9c56-1ce0-4051-a147-e3eb39cacde2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df6.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd6117-6887-4e44-986c-227f4215cf52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_drop = ['week_of_year', 'day', 'month', 'day_of_week', 'promo_since','competition_since', 'year_week' ]\n",
    "df6 = df6.drop( cols_drop, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfae7f61-21f5-4ab3-bf36-a6669bfa95bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training dataset\n",
    "X_train = df6[df6['date'] < '2015-06-19']\n",
    "y_train = X_train['sales']\n",
    "# test dataset\n",
    "X_test = df6[df6['date'] >= '2015-06-19']\n",
    "y_test = X_test['sales']\n",
    "print( 'Training Min Date: {}'.format( X_train['date'].min() ) )\n",
    "print( 'Training Max Date: {}'.format( X_train['date'].max() ) )\n",
    "print( '\\nTest Min Date: {}'.format( X_test['date'].min() ) )\n",
    "print( 'Test Max Date: {}'.format( X_test['date'].max() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6071df62-f6fb-43bf-b5c6-11e1636144eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6.2. Boruta as Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b0ddc-e0c2-43a7-863b-1f723d29eb90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##training and test dataset for Boruta\n",
    "#X_train_n = X_train.drop( ['date', 'sales'], axis=1 ).values\n",
    "#y_train_n = y_train.values.ravel()\n",
    "\n",
    "##define RandomForestRegressor\n",
    "#rf = RandomForestRegressor( n_jobs=-1 )\n",
    "\n",
    "##define Boruta\n",
    "#boruta = BorutaPy( rf, n_estimators='auto', verbose=2, random_state=42 ).fit(X_train_n, y_train_n )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86baba63-f3e0-448e-a276-e88fc8966721",
   "metadata": {},
   "source": [
    "### 6.2.1. Best Features from Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a3900-8c4e-4f2e-af2c-71dde7ab9e26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_selected = boruta.support_.tolist()\n",
    "\n",
    "## best features\n",
    "X_train_fs = X_train.drop( ['date', 'sales'], axis=1 )\n",
    "cols_selected_boruta = X_train_fs.iloc[:, cols_selected].columns.to_list()\n",
    "\n",
    "# not selected boruta\n",
    "cols_not_selected_boruta = list( np.setdiff1d( X_train_fs.columns,cols_selected_boruta ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f1037e-9ed1-42a9-bd84-2bf26dd9f663",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6.3. Manual Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a674af-53b1-4006-bcc9-e8705b41bd8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_selected_boruta = ['store', 'promo','store_type','assortment','competition_distance',\n",
    "                         'competition_open_since_month','competition_open_since_year','promo2',\n",
    "                         'promo2_since_week','promo2_since_year','competition_time_month','promo_time_week',\n",
    "                         'day_of_week_sin','day_of_week_cos','month_sin','month_cos','day_sin','day_cos',\n",
    "                         'week_of_year_sin','week_of_year_cos','year','school_holiday']\n",
    "# columns to add\n",
    "feat_to_add = ['date', 'sales']\n",
    "cols_selected_boruta_full = cols_selected_boruta.copy()\n",
    "cols_selected_boruta_full.extend( feat_to_add )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdc52d5-1747-4f2f-acaf-95b90803d6eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 7.0. PASSO 07 - MACHINE LEARNING MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaef574-86b4-4eec-a8a2-d09086294669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = X_train[ cols_selected_boruta ]\n",
    "x_test = X_test[ cols_selected_boruta ]\n",
    "\n",
    "# Time Series Data Preparation\n",
    "x_training = X_train[ cols_selected_boruta_full ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a522b21-dd7b-4a91-939e-4def316f4039",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7.1. Average Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c186fcde-a526-47c5-80a4-a7182110f175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux1 = x_test.copy()\n",
    "aux1['sales'] = y_test.copy()\n",
    "# prediction\n",
    "aux2 = aux1[['store', 'sales']].groupby( 'store' ).mean().reset_index().rename(columns={'sales': 'predictions'} )\n",
    "aux1 = pd.merge( aux1, aux2, how='left', on='store' )\n",
    "yhat_baseline = aux1['predictions']\n",
    "# performance\n",
    "baseline_result = ml_error( 'Average Model', np.expm1( y_test ), np.expm1(yhat_baseline ) )\n",
    "baseline_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4f024-531c-4a26-ba20-cb9d9eb6ec58",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7.2. Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f000bdd8-983a-4ad5-8cb6-472235b7125c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model\n",
    "lr = LinearRegression().fit( x_train, y_train )\n",
    "# prediction\n",
    "yhat_lr = lr.predict( x_test )\n",
    "# performance\n",
    "lr_result = ml_error( 'Linear Regression', np.expm1( y_test ), np.expm1(yhat_lr ) )\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691f4135-921b-42ed-ac0a-b39bf065dd2f",
   "metadata": {},
   "source": [
    "### 7.2.1. Linear Regression Model - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1cd3c8-fbff-481b-a0c8-0571bea7daf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_result_cv = cross_validation( x_training, 5, 'Linear Regression', lr,verbose=False )\n",
    "lr_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6242e85f-dbc7-4b38-97ea-d1e10771625f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7.3. Linear Regression Regularized Model - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53077509-2797-4edc-b8a2-daca460d42fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model\n",
    "lrr = Lasso( alpha=0.01 ).fit( x_train, y_train )\n",
    "# prediction\n",
    "yhat_lrr = lrr.predict( x_test )\n",
    "# performance\n",
    "lrr_result = ml_error( 'Linear Regression - Lasso', np.expm1( y_test ), np.expm1( yhat_lrr ) )\n",
    "lrr_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9b604b-b8dd-4146-b22d-93cfb90ab788",
   "metadata": {},
   "source": [
    "### 7.3.1. Lasso - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67d6c4f-c2f0-46a9-8d21-8f3ec5c53140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrr_result_cv = cross_validation( x_training, 5, 'Lasso', lrr, verbose=False )\n",
    "lrr_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7507c6ef-368e-4f8f-8e1e-64425381056a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7.4. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def0516-2a5e-446a-bd70-a33b9b790efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model\n",
    "rf = RandomForestRegressor( n_estimators=100, n_jobs=-1, random_state=42 ).fit(x_train, y_train )\n",
    "# prediction\n",
    "yhat_rf = rf.predict( x_test )\n",
    "# performance\n",
    "rf_result = ml_error( 'Random Forest Regressor', np.expm1( y_test ), np.expm1(yhat_rf ) )\n",
    "rf_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1a4a0f-ac06-4b62-a127-6d8a4e8bcf89",
   "metadata": {},
   "source": [
    "### 7.4.1. Random Forest Regressor - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcfefed-0efb-4da5-865f-c1546a6bf307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_result_cv = cross_validation( x_training, 5, 'Random Forest Regressor', rf,verbose=True )\n",
    "rf_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aba6a7-dc1a-4f60-ae10-83bd20f0baf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7.5. XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087ff65-bb1b-45bb-948d-ba94611627f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model_xgb = xgb.XGBRegressor( objective='reg:squarederror' ).fit( x_train, y_train )\n",
    "# prediction\n",
    "yhat_xgb = model_xgb.predict( x_test )\n",
    "# performance\n",
    "xgb_result = ml_error( 'XGBoost Regressor', np.expm1( y_test ), np.expm1(yhat_xgb ) )\n",
    "xgb_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8565e00c-2b08-4995-ad99-ae9a92f1456d",
   "metadata": {},
   "source": [
    "### 7.5.1. XGBoost Regressor - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e67d92-829a-4379-ba37-8e371c9b416e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_result_cv = cross_validation( x_training, 5, 'XGBoost Regressor',model_xgb, verbose=True )\n",
    "xgb_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e336c4d-bb2f-45bf-9843-fa784a79947d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7.6. Compare Model’s Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2f8604-6ccd-48e2-8d93-efbc21c8c108",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 7.6.1. Single Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb140d8c-e348-4682-8199-a488ce1fcf25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelling_result = pd.concat( [baseline_result, lr_result, lrr_result,rf_result, xgb_result] )\n",
    "modelling_result.sort_values( 'RMSE' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be356c7f-bf52-4f30-8966-b9200852ac94",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 7.6.2. Real Performance - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b18e96d-7497-4143-9c2c-1ff80f9e79b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelling_result_cv = pd.concat( [lr_result_cv, lrr_result_cv, rf_result_cv,xgb_result_cv] )\n",
    "modelling_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f62b6-22b4-4371-aede-e99b19dac04f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 8.0. PASSO 08 - HYPERPARAMETER FINE TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9246089-e840-4843-a856-31b120cb491d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 8.1. Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b4f9b-3c17-47d0-bf95-2ca089e16e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param = {\n",
    " 'n_estimators': [1500, 1700, 2400, 2800, 3000],\n",
    " 'eta': [0.01, 0.03],\n",
    " 'max_depth': [3, 5, 9],\n",
    " 'subsample': [0.1, 0.5, 0.7],\n",
    " 'colsample_bytree': [0.3, 0.7, 0.9],\n",
    " 'min_child_weight': [3, 8, 15]\n",
    " }\n",
    "\n",
    "MAX_EVAL = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b935c-9f0a-48f4-b5c9-28c6b036244a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#final_result = pd.DataFrame()\n",
    "\n",
    "#for i in range( MAX_EVAL ):\n",
    "    # choose values for parameters randomly\n",
    "#    hp = { k: random.sample( v, 1 )[0] for k, v in param.items() }\n",
    " #   print( hp )\n",
    "    #\n",
    "    # # model\n",
    "#    model_xgb = xgb.XGBRegressor( objective='reg:squarederror',\n",
    "#    n_estimators=hp['n_estimators'],\n",
    "#    eta=hp['eta'],\n",
    "#    max_depth=hp['max_depth'],\n",
    "#    subsample=hp['subsample'],\n",
    "#    colsample_bytree=hp['colsample_bytree'],\n",
    "#    min_child_weight=hp['min_child_weight'] )\n",
    "\n",
    "    # performance\n",
    "#    result = cross_validation( x_training, 5, 'XGBoost Regressor', model_xgb,verbose=True )\n",
    "#    final_result = pd.concat( [final_result, result] )\n",
    "\n",
    "#final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b40d52-c9e6-473a-8782-fb58dd085633",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 8.2. Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc368e8-f985-498e-9889-8eee7a7d6a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_tuned = {\n",
    "'n_estimators': 1500,\n",
    "'eta': 0.03,\n",
    "'max_depth': 9,\n",
    "'subsample': 0.7,\n",
    "'colsample_bytree': 0.3,\n",
    "'min_child_weight': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be8778c-7cad-4db9-a93d-fff9eba48cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model_xgb_tuned = xgb.XGBRegressor( objective='reg:squarederror',\n",
    "n_estimators=param_tuned['n_estimators'],\n",
    "eta=param_tuned['eta'],\n",
    "max_depth=param_tuned['max_depth'],\n",
    "subsample=param_tuned['subsample'],colsample_bytree=param_tuned['colsample_bytree'],\n",
    "                                   min_child_weight=param_tuned['min_child_weight'] ).fit( x_train, y_train )\n",
    "# prediction\n",
    "yhat_xgb_tuned = model_xgb_tuned.predict( x_test )\n",
    "# performance\n",
    "xgb_result_tuned = ml_error( 'XGBoost Regressor', np.expm1( y_test ), np.expm1(yhat_xgb_tuned ) )\n",
    "xgb_result_tuned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c0025-48a0-4c25-9c88-e92b21c1b6d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 9.0. PASSO 09 - TRADUCAO E INTERPRETACAO DO ERRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb1eb0-eb35-4c50-95f1-dbc7dae5fd43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9 = X_test[ cols_selected_boruta_full ]\n",
    "df9 = df9.copy()\n",
    "# rescale\n",
    "df9['sales'] = np.expm1( df9['sales'] )\n",
    "df9['predictions'] = np.expm1( yhat_xgb_tuned )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faf7fb4-9451-4a4c-bf4e-5ba5cd82ceb5",
   "metadata": {},
   "source": [
    "## 9.1. Business Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3627a0b-804e-48af-841c-e56baaf8d6d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sum of predictions\n",
    "df91 = df9[['store', 'predictions']].groupby( 'store' ).sum().reset_index()\n",
    "# MAE and MAPE\n",
    "df9_aux1 = df9[['store', 'sales', 'predictions']].groupby( 'store' ).apply(lambda x: \n",
    "                    mean_absolute_error( x['sales'], x['predictions'] ) ).reset_index().rename( columns={0:'MAE'})\n",
    "df9_aux2 = df9[['store', 'sales', 'predictions']].groupby( 'store' ).apply(lambda x: \n",
    "                    mean_absolute_percentage_error( x['sales'], x['predictions'] ) ).reset_index().rename( columns={0:'MAPE'})\n",
    "# Merge\n",
    "df9_aux3 = pd.merge( df9_aux1, df9_aux2, how='inner', on='store' )\n",
    "df92 = pd.merge( df91, df9_aux3, how='inner', on='store' )\n",
    "# Scenarios\n",
    "df92['worst_scenario'] = df92['predictions'] - df92['MAE']\n",
    "df92['best_scenario'] = df92['predictions'] + df92['MAE']\n",
    "# order columns\n",
    "df92 = df92[['store', 'predictions', 'worst_scenario', 'best_scenario', 'MAE','MAPE']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ee264-959f-46a4-a227-ceeb15d23f0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df92.sort_values( 'MAPE', ascending=True ).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a857da-e068-4b0d-80f0-0e78c74ac476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot( x='store', y='MAPE', data=df92 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f06e40-3613-4699-9d4d-d935248e3824",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 9.2. Total Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df602ef5-f92b-42a9-bdfa-dc0ac8a8b108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df93 = df92[['predictions', 'worst_scenario', 'best_scenario']].apply( lambda x: \n",
    "        np.sum( x ), axis=0 ).reset_index().rename( columns={'index': 'Scenario', 0:'Values'} )\n",
    "df93['Values'] = df93['Values'].map( 'R${:,.2f}'.format )\n",
    "df93"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f67789-5d54-469a-95db-1ded88004d42",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 9.3. Machine Learning Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cafc44-6550-4251-8c5d-de8a03180494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df9['error'] = df9['sales'] - df9['predictions']\n",
    "df9['error_rate'] = df9['predictions'] / df9['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1573d-099e-4e39-90de-42547e46ec4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.subplot( 2, 2, 1 )\n",
    "sns.lineplot( x='date', y='sales', data=df9, label='SALES' )\n",
    "sns.lineplot( x='date', y='predictions', data=df9, label='PREDICTIONS' )\n",
    "\n",
    "plt.subplot( 2, 2, 2 )\n",
    "sns.lineplot( x='date', y='error_rate', data=df9 )\n",
    "plt.axhline( 1, linestyle='--')\n",
    "\n",
    "plt.subplot( 2, 2, 3 )\n",
    "sns.distplot( df9['error'] )\n",
    "\n",
    "plt.subplot( 2, 2, 4 )\n",
    "sns.scatterplot(x=df9['predictions'], y=df9['error'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564a9ea7-812f-437f-99ac-f7c064cb48b4",
   "metadata": {},
   "source": [
    "# 10.0. PASSO 10 - DEPLOY MODEL TO PRODUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0c5fc-78a9-4468-892b-395c4c2aa33e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save Trained Model\n",
    "pickle.dump( model_xgb_tuned, open('C:\\\\Users\\\\michele\\\\projetos\\\\repos\\\\ds_em_producao\\\\model\\\\model_rossmann.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9eddc7-bf52-48e2-91fc-c07a12b4fc71",
   "metadata": {},
   "source": [
    "## 10.1. Rossmann Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae42dc7-3e74-4bb8-92f3-bdf578ae0bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import inflection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "\n",
    "class Rossmann( object ):\n",
    "    def __init__( self ):\n",
    "        self.home_path='C:\\\\Users\\\\michele\\\\projetos\\\\repos\\\\ds_em_producao'\n",
    "        self.competition_distance_scaler = pickle.load( open( self.home_path + '\\\\parameter\\\\competition_distance_scaler.pkl', 'rb') )\n",
    "        self.competition_time_month_scaler = pickle.load( open( self.home_path + '\\\\parameter\\\\competition_time_month_scaler.pkl', 'rb') )\n",
    "        self.promo_time_week_scaler = pickle.load( open( self.home_path + '\\\\parameter\\\\promo_time_week_scaler.pkl', 'rb') )\n",
    "        self.year_scaler = pickle.load( open( self.home_path + '\\\\parameter\\\\year_scaler.pkl', 'rb') )\n",
    "        self.store_type_scaler = pickle.load( open( self.home_path + '\\\\parameter\\\\store_type_scaler.pkl', 'rb') )\n",
    "    def data_cleaning( self, df1 ):\n",
    "        ## 1.1. Rename Columns\n",
    "        cols_old = ['Store', 'DayOfWeek', 'Date', 'Open', 'Promo','StateHoliday', 'SchoolHoliday',\n",
    "        'StoreType', 'Assortment', 'CompetitionDistance','CompetitionOpenSinceMonth',\n",
    "        'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek','Promo2SinceYear', 'PromoInterval']\n",
    "        snakecase = lambda x: inflection.underscore( x )\n",
    "        cols_new = list( map( snakecase, cols_old ) )\n",
    "        # rename\n",
    "        df1.columns = cols_new\n",
    "        ## 1.3. Data Types\n",
    "        df1['date'] = pd.to_datetime( df1['date'] )\n",
    "        ## 1.5. Fillout NA\n",
    "        #competition_distance\n",
    "        df1['competition_distance'] = df1['competition_distance'].apply( lambda x: 200000.0 if math.isnan( x ) else x )\n",
    "        #competition_open_since_month\n",
    "        df1['competition_open_since_month'] = df1.apply( lambda x: \n",
    "                                        x['date'].month if math.isnan( x['competition_open_since_month'] ) else \n",
    "                                        x['competition_open_since_month'], axis=1 )\n",
    "        #competition_open_since_year\n",
    "        df1['competition_open_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( \n",
    "            x['competition_open_since_year'] ) else x['competition_open_since_year'], axis=1 )\n",
    "        #promo2_since_week\n",
    "        df1['promo2_since_week'] = df1.apply( lambda x: x['date'].week if math.isnan( \n",
    "            x['promo2_since_week'] ) else x['promo2_since_week'], axis=1 )\n",
    "        #promo2_since_year\n",
    "        df1['promo2_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( \n",
    "            x['promo2_since_year'] ) else x['promo2_since_year'], axis=1 )\n",
    "        #promo_interval\n",
    "        month_map = {1: 'Jan', 2: 'Fev', 3: 'Mar', 4: 'Apr', 5: 'May', 6:'Jun', \n",
    "                     7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "        df1['promo_interval'].fillna(0, inplace=True )\n",
    "        df1['month_map'] = df1['date'].dt.month.map( month_map )\n",
    "        df1['is_promo'] = df1[['promo_interval', 'month_map']].apply( lambda x:0 if \n",
    "                        x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split( ',' ) else 0, axis=1 )\n",
    "        ## 1.6. Change Data Types\n",
    "        # competiton\n",
    "        df1['competition_open_since_month'] = df1['competition_open_since_month'].astype( int )\n",
    "        df1['competition_open_since_year'] = df1['competition_open_since_year'].astype( int )\n",
    "        # promo2\n",
    "        df1['promo2_since_week'] = df1['promo2_since_week'].astype( int )\n",
    "        df1['promo2_since_year'] = df1['promo2_since_year'].astype( int )\n",
    "        return df1\n",
    "    def feature_engineering( self, df2 ):\n",
    "        # year\n",
    "        df2['year'] = df2['date'].dt.year\n",
    "        # month\n",
    "        df2['month'] = df2['date'].dt.month\n",
    "\n",
    "        # day\n",
    "        df2['day'] = df2['date'].dt.day\n",
    "        # week of year\n",
    "        df2['week_of_year'] = df2['date'].dt.weekofyear\n",
    "        # year week\n",
    "        df2['year_week'] = df2['date'].dt.strftime( '%Y-%W' )\n",
    "        # competition since\n",
    "        df2['competition_since'] = df2.apply( lambda x: datetime.datetime(year=x['competition_open_since_year'],\n",
    "                                            month=x['competition_open_since_month'],day=1 ), axis=1 )\n",
    "        df2['competition_time_month'] = ( ( df2['date'] - df2['competition_since'] )/30 ).apply(\n",
    "                                            lambda x: x.days ).astype( int )\n",
    "        # promo since\n",
    "        df2['promo_since'] = df2['promo2_since_year'].astype( str ) + '-' + df2['promo2_since_week'].astype( str )\n",
    "        df2['promo_since'] = df2['promo_since'].apply( lambda x: datetime.datetime.strptime(\n",
    "                                    x + '-1', '%Y-%W-%w' ) - datetime.timedelta( days=7 ) )\n",
    "        df2['promo_time_week'] = ( ( df2['date'] - df2['promo_since'] )/7 ).apply( lambda x: x.days ).astype( int )\n",
    "        # assortment\n",
    "        df2['assortment'] = df2['assortment'].apply( lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended' )\n",
    "        # state holiday\n",
    "        df2['state_holiday'] = df2['state_holiday'].apply( lambda x:'public_holiday' \n",
    "                            if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day' )\n",
    "        # 3.0. PASSO 03 - FILTRAGEM DE VARIÁVEIS\n",
    "        ## 3.1. Filtragem das Linhas\n",
    "        df2 = df2[df2['open'] != 0]\n",
    "        ## 3.2. Selecao das Colunas\n",
    "        cols_drop = ['open', 'promo_interval', 'month_map']\n",
    "        df2 = df2.drop( cols_drop, axis=1 )\n",
    "        return df2\n",
    "    def data_preparation( self, df5 ):\n",
    "        ## 5.2. Rescaling\n",
    "        # competition distance\n",
    "        df5['competition_distance'] = self.competition_distance_scaler.fit_transform( \n",
    "                                    df5[['competition_distance']].values )\n",
    "        # competition time month\n",
    "        df5['competition_time_month'] = self.competition_time_month_scaler.fit_transform( \n",
    "                                        df5[['competition_time_month']].values )\n",
    "        # promo time week\n",
    "        df5['promo_time_week'] = self.promo_time_week_scaler.fit_transform(df5[['promo_time_week']].values )\n",
    "        # year\n",
    "        df5['year'] = self.year_scaler.fit_transform( df5[['year']].values )\n",
    "        ### 5.3.1. Encoding\n",
    "        # state_holiday - One Hot Encoding\n",
    "        df5 = pd.get_dummies( df5, prefix=['state_holiday'], columns=['state_holiday'] )\n",
    "        # store_type - Label Encoding\n",
    "        df5['store_type'] = self.store_type_scaler.fit_transform(df5['store_type'] )\n",
    "        # assortment - Ordinal Encoding\n",
    "        assortment_dict = {'basic': 1, 'extra': 2, 'extended': 3}\n",
    "        df5['assortment'] = df5['assortment'].map( assortment_dict )\n",
    "        ### 5.3.3. Nature Transformation\n",
    "        # day of week\n",
    "        df5['day_of_week_sin'] = df5['day_of_week'].apply( lambda x: np.sin( x * ( 2. * np.pi/7 ) ) )\n",
    "        df5['day_of_week_cos'] = df5['day_of_week'].apply( lambda x: np.cos( x * ( 2. * np.pi/7 ) ) )\n",
    "        # month\n",
    "        df5['month_sin'] = df5['month'].apply( lambda x: np.sin( x * ( 2. * np.pi/12 ) ) )\n",
    "        df5['month_cos'] = df5['month'].apply( lambda x: np.cos( x * ( 2. * np.pi/12 ) ) )\n",
    "        # day\n",
    "        df5['day_sin'] = df5['day'].apply( lambda x: np.sin( x * ( 2. * np.pi/30 ) ) )\n",
    "        df5['day_cos'] = df5['day'].apply( lambda x: np.cos( x * ( 2. * np.pi/30 ) ) )\n",
    "        # week of year\n",
    "        df5['week_of_year_sin'] = df5['week_of_year'].apply( lambda x: np.sin(x * ( 2. * np.pi/52 ) ) )\n",
    "        df5['week_of_year_cos'] = df5['week_of_year'].apply( lambda x: np.cos(x * ( 2. * np.pi/52 ) ) )\n",
    "        cols_selected = ['store', 'promo','store_type','assortment','competition_distance',\n",
    "                         'competition_open_since_month','competition_open_since_year','promo2',\n",
    "                         'promo2_since_week','promo2_since_year','competition_time_month','promo_time_week',\n",
    "                         'day_of_week_sin','day_of_week_cos','month_sin','month_cos','day_sin','day_cos',\n",
    "                         'week_of_year_sin','week_of_year_cos','year','school_holiday']\n",
    "        return df5[ cols_selected ]\n",
    "    def get_prediction( self, model, original_data, test_data ):\n",
    "        # prediction\n",
    "        pred = model.predict( test_data )\n",
    "        # join pred into the original data\n",
    "        original_data['prediction'] = np.expm1( pred )\n",
    "        return original_data.to_json( orient='records', date_format='iso' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf06aab2-079a-4174-b144-cf56004c97a9",
   "metadata": {},
   "source": [
    "## 10.2. API Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b5e59d-c3db-4254-b5cf-67c9c4d1c946",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.0.48:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from flask import Flask, request, Response\n",
    "from api.rossmann.Rossmann import Rossmann\n",
    "\n",
    "# loading model\n",
    "model = pickle.load( open( 'C:\\\\Users\\\\michele\\\\projetos\\\\repos\\\\ds_em_producao\\\\model\\\\model_rossmann.pkl', 'rb') )\n",
    "# initialize API\n",
    "app = Flask( __name__ )\n",
    "@app.route( '/rossmann/predict', methods=['POST'] )\n",
    "\n",
    "def rossmann_predict():\n",
    "    test_json = request.get_json()\n",
    "    if test_json: # there is data\n",
    "        if isinstance( test_json, dict ): # unique example\n",
    "            test_raw = pd.DataFrame( test_json, index=[0] )\n",
    "        else: # multiple example\n",
    "            test_raw = pd.DataFrame( test_json, columns=test_json[0].keys() )\n",
    "            # Instantiate Rossmann class\n",
    "            pipeline = Rossmann()\n",
    "            # data cleaning\n",
    "            df1 = pipeline.data_cleaning( test_raw )\n",
    "            # feature engineering\n",
    "            df2 = pipeline.feature_engineering( df1 )\n",
    "            # data preparation\n",
    "            df3 = pipeline.data_preparation( df2 )\n",
    "            # prediction\n",
    "            df_response = pipeline.get_prediction( model, test_raw, df3 )\n",
    "            return df_response\n",
    "    else:\n",
    "        return Reponse( '{}', status=200, mimetype='application\\\\json' )\n",
    "if __name__ == '__main__':\n",
    "    app.run( '0.0.0.0' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf6c2fb-a23d-43bf-8b16-e37c572b548f",
   "metadata": {},
   "source": [
    "## 10.3. API Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d0b1dd1-52c0-40ca-97d0-03e4ee19181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading test dataset\n",
    "df10 = pd.read_csv( 'C:\\\\Users\\\\michele\\\\projetos\\\\repos\\\\ds_em_producao\\\\data\\\\test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c5b04d7-ce22-4d7a-a146-4de4126cda22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge test dataset + store\n",
    "df_test = pd.merge( df10, df_store_raw, how='left', on='Store' )\n",
    "# choose store for prediction\n",
    "df_test = df_test[df_test['Store'].isin( [1, 42, 22] )]\n",
    "# remove closed days\n",
    "df_test = df_test[df_test['Open'] != 0]\n",
    "df_test = df_test[~df_test['Open'].isnull()]\n",
    "df_test = df_test.drop( 'Id', axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c937d0a4-0d63-4314-bb66-cc1ce8f462f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Dataframe to json\n",
    "data = json.dumps( df_test.to_dict( orient='records' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cbc1c8bd-1223-42cd-ab7d-d976e64c5972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code 200\n"
     ]
    }
   ],
   "source": [
    "# API Call\n",
    "#url = 'http://127.0.0.1:5000/rossmann/predict'\n",
    "url = 'https://rossmann-api-oy3p.onrender.com/rossmann/predict'\n",
    "header = {'Content-type': 'application/json' }\n",
    "data = data\n",
    "r = requests.post( url, data=data, headers=header )\n",
    "print( 'Status Code {}'.format( r.status_code ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07a50d2a-b088-413d-9c39-c8087e4abea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.DataFrame( r.json(), columns=r.json()[0].keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9e9dae4-e572-4c75-9da8-eee73b43f4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store Number 1 will sell R$210,539.15 in the next 6 weeks\n",
      "Store Number 22 will sell R$158,382.29 in the next 6 weeks\n",
      "Store Number 42 will sell R$231,835.83 in the next 6 weeks\n"
     ]
    }
   ],
   "source": [
    "d2 = d1[['store', 'prediction']].groupby( 'store' ).sum().reset_index()\n",
    "for i in range( len( d2 ) ):\n",
    "    print( 'Store Number {} will sell R${:,.2f} in the next 6 weeks'.format(\n",
    "    d2.loc[i, 'store'],\n",
    "    d2.loc[i, 'prediction'] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62ee8073-7b82-4bc6-972f-a9d7ae3e289a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>promo</th>\n",
       "      <th>state_holiday</th>\n",
       "      <th>school_holiday</th>\n",
       "      <th>store_type</th>\n",
       "      <th>assortment</th>\n",
       "      <th>competition_distance</th>\n",
       "      <th>competition_open_since_month</th>\n",
       "      <th>competition_open_since_year</th>\n",
       "      <th>promo2</th>\n",
       "      <th>promo2_since_week</th>\n",
       "      <th>promo2_since_year</th>\n",
       "      <th>promo_interval</th>\n",
       "      <th>month_map</th>\n",
       "      <th>is_promo</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>year_week</th>\n",
       "      <th>competition_since</th>\n",
       "      <th>competition_time_month</th>\n",
       "      <th>promo_since</th>\n",
       "      <th>promo_time_week</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17T00:00:00.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>regular_day</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>basic</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Sep</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>2015-37</td>\n",
       "      <td>2008-09-01T00:00:00.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2015-09-14T00:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>5465.583008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17T00:00:00.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>regular_day</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>basic</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2012</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "      <td>Sep</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>2015-37</td>\n",
       "      <td>2015-09-01T00:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-05-21T00:00:00.000</td>\n",
       "      <td>173</td>\n",
       "      <td>4100.945801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17T00:00:00.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>regular_day</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>extended</td>\n",
       "      <td>290.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2011</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "      <td>Sep</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>2015-37</td>\n",
       "      <td>2015-09-01T00:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-09-26T00:00:00.000</td>\n",
       "      <td>207</td>\n",
       "      <td>5470.741699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-09-16T00:00:00.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>regular_day</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>basic</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>Sep</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>2015-37</td>\n",
       "      <td>2008-09-01T00:00:00.000</td>\n",
       "      <td>85</td>\n",
       "      <td>2015-09-14T00:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>5636.498047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-09-16T00:00:00.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>regular_day</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>basic</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2012</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "      <td>Sep</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>2015-37</td>\n",
       "      <td>2015-09-01T00:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-05-21T00:00:00.000</td>\n",
       "      <td>173</td>\n",
       "      <td>4141.697754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  day_of_week                     date  open  promo state_holiday  school_holiday store_type assortment  competition_distance  competition_open_since_month  competition_open_since_year  promo2  promo2_since_week  promo2_since_year   promo_interval month_map  is_promo  year  month  day  week_of_year year_week        competition_since  competition_time_month              promo_since  promo_time_week   prediction\n",
       "0      1            4  2015-09-17T00:00:00.000   1.0      1   regular_day               0          c      basic                1270.0                             9                         2008       0                 38               2015                0       Sep         0  2015      9   17            38   2015-37  2008-09-01T00:00:00.000                      85  2015-09-14T00:00:00.000                0  5465.583008\n",
       "1     22            4  2015-09-17T00:00:00.000   1.0      1   regular_day               0          a      basic                1040.0                             9                         2015       1                 22               2012  Jan,Apr,Jul,Oct       Sep         0  2015      9   17            38   2015-37  2015-09-01T00:00:00.000                       0  2012-05-21T00:00:00.000              173  4100.945801\n",
       "2     42            4  2015-09-17T00:00:00.000   1.0      1   regular_day               0          a   extended                 290.0                             9                         2015       1                 40               2011  Jan,Apr,Jul,Oct       Sep         0  2015      9   17            38   2015-37  2015-09-01T00:00:00.000                       0  2011-09-26T00:00:00.000              207  5470.741699\n",
       "3      1            3  2015-09-16T00:00:00.000   1.0      1   regular_day               0          c      basic                1270.0                             9                         2008       0                 38               2015                0       Sep         0  2015      9   16            38   2015-37  2008-09-01T00:00:00.000                      85  2015-09-14T00:00:00.000                0  5636.498047\n",
       "4     22            3  2015-09-16T00:00:00.000   1.0      1   regular_day               0          a      basic                1040.0                             9                         2015       1                 22               2012  Jan,Apr,Jul,Oct       Sep         0  2015      9   16            38   2015-37  2015-09-01T00:00:00.000                       0  2012-05-21T00:00:00.000              173  4141.697754"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17625bcd-652c-45df-93e7-e2afaa4bff93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_em_producao",
   "language": "python",
   "name": "ds_em_producao"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
